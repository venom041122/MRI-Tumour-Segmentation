{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc5170f-4aa0-40ed-8ea5-6bdcad1280a2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1599bef-b2ad-4615-9ac2-fd8c0af92c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Couldn't find a Git repository in '/home/jovyan' nor in any parent directory. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/prakhar-agarwal-byte/tumor-segmentation/b0d2e993579e4fec8935be62676d34cb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import comet_ml at the top of your file\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key=\"9vyoHvz6rwbLc09Gu2QbbFPAV\",\n",
    "    project_name=\"tumor-segmentation\",\n",
    "    workspace=\"prakhar-agarwal-byte\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe286a2-ea63-43eb-a417-881f4efa2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce2b5f32-ef52-416c-ba6a-7922801bae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n",
    "    ):\n",
    "        super(UNET, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Down part of UNET\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Up part of UNET\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2, feature, kernel_size=2, stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b9bf10-65ab-4a18-9cb5-e2d8cc860448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    x = torch.randn((3, 1, 161, 161))\n",
    "    model = UNET(in_channels=1, out_channels=1)\n",
    "    preds = model(x)\n",
    "    assert preds.shape == x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d25c0d-bb84-44f0-b653-fef3983ddaf8",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd5d2a72-437c-4936-93fc-66e454b30810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba70c5cc-38a7-483a-8bfd-5b9a6c511e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.image_dir, self.images[index])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[index].replace(\".tif\", \"_mask.tif\"))\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
    "        mask[mask == 255.0] = 1.0\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentations = self.transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "        \n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b1eea-a6d9-44c1-9695-afbc29e92f41",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a33a590-294b-48c6-942c-7d3e5e2c33cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(checkpoint, model):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "def get_loaders(\n",
    "        train_dir,\n",
    "        train_maskdir,\n",
    "        val_dir,\n",
    "        val_maskdir,\n",
    "        batch_size,\n",
    "        train_transform,\n",
    "        val_transform,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "):\n",
    "    train_ds = MRIDataset(\n",
    "        image_dir=train_dir,\n",
    "        mask_dir=train_maskdir,\n",
    "        transform=train_transform,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_ds = MRIDataset(\n",
    "        image_dir=val_dir,\n",
    "        mask_dir=val_maskdir,\n",
    "        transform=val_transform,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def check_accuracy(loader, model, mode, epoch, device=\"cuda\"):\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    dice_score = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).unsqueeze(1)\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_pixels += torch.numel(preds)\n",
    "            dice_score += (2 * (preds * y).sum()) / (\n",
    "                (preds + y).sum() + 1e-8\n",
    "            )\n",
    "\n",
    "    print(\n",
    "        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n",
    "    )\n",
    "    print(f\"Dice score: {dice_score/len(loader)}\")\n",
    "    experiment.log_metric(f\"{mode}_dice_score\", dice_score/len(loader), step=epoch)\n",
    "    experiment.log_metric(f\"{mode}_accuracy\", num_correct/num_pixels*100, step=epoch)\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def save_predictions_as_imgs(\n",
    "    loader, model, folder=\"saved_images/\", device=\"cuda\"\n",
    "):\n",
    "    model.eval()\n",
    "    for idx, (x, y) in enumerate(loader):\n",
    "        x = x.to(device=device)\n",
    "        with torch.no_grad():\n",
    "            preds = torch.sigmoid(model(x))\n",
    "            preds = (preds > 0.5).float()\n",
    "        torchvision.utils.save_image(\n",
    "            preds, f\"{folder}pred_{idx}.png\"\n",
    "        )\n",
    "        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c879834-7068-4f1a-a448-c3d50c94418d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7085c402-d782-4f05-a343-7516ec37f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameters etc.\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = True\n",
    "TRAIN_IMG_DIR = \"MRI Dataset/train_images\"\n",
    "TRAIN_MASK_DIR = \"MRI Dataset/train_mask\"\n",
    "VAL_IMG_DIR = \"MRI Dataset/val_images\"\n",
    "VAL_MASK_DIR = \"MRI Dataset/val_mask\"\n",
    "\n",
    "\n",
    "# Report multiple hyperparameters using a dictionary:\n",
    "hyper_params = {\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "}\n",
    "experiment.log_parameters(hyper_params)\n",
    "\n",
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=DEVICE)\n",
    "        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
    "\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Rotate(limit=35, p=1.0),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.1),\n",
    "            A.Normalize(\n",
    "                mean=[0.0, 0.0, 0.0],\n",
    "                std=[1.0, 1.0, 1.0],\n",
    "                max_pixel_value=255.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    val_transforms = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Normalize(\n",
    "                mean=[0.0, 0.0, 0.0],\n",
    "                std=[1.0, 1.0, 1.0],\n",
    "                max_pixel_value=255.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    train_loader, val_loader = get_loaders(\n",
    "        TRAIN_IMG_DIR,\n",
    "        TRAIN_MASK_DIR,\n",
    "        VAL_IMG_DIR,\n",
    "        VAL_MASK_DIR,\n",
    "        BATCH_SIZE,\n",
    "        train_transform,\n",
    "        val_transforms,\n",
    "        NUM_WORKERS,\n",
    "        PIN_MEMORY,\n",
    "    )\n",
    "\n",
    "    if LOAD_MODEL:\n",
    "        load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "        # save model\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\":optimizer.state_dict(),\n",
    "        }\n",
    "        save_checkpoint(checkpoint)\n",
    "\n",
    "        # check accuracy\n",
    "        check_accuracy(train_loader, model, \"training\", epoch, device=DEVICE)\n",
    "        check_accuracy(val_loader, model, \"validation\", epoch, device=DEVICE)\n",
    "        \n",
    "        # print some examples to a folder\n",
    "        save_predictions_as_imgs(\n",
    "            val_loader, model, folder=\"saved_images/\", device=DEVICE\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3df93d-d594-4e48-b3da-34c15be20295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:51<00:00,  1.85s/it, loss=0.0232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 250358442/250937344 with acc 99.77\n",
      "Dice score: 0.8803378343582153\n",
      "Got 6539253/6553600 with acc 99.78\n",
      "Dice score: 0.8869966864585876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:56<00:00,  1.93s/it, loss=0.0207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 250414647/250937344 with acc 99.79\n",
      "Dice score: 0.8969385027885437\n",
      "Got 6539706/6553600 with acc 99.79\n",
      "Dice score: 0.8952927589416504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:55<00:00,  1.93s/it, loss=0.0176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 250398557/250937344 with acc 99.79\n",
      "Dice score: 0.8888599276542664\n",
      "Got 6539800/6553600 with acc 99.79\n",
      "Dice score: 0.8900848627090454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:55<00:00,  1.93s/it, loss=0.015] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 250400483/250937344 with acc 99.79\n",
      "Dice score: 0.8939995169639587\n",
      "Got 6540295/6553600 with acc 99.80\n",
      "Dice score: 0.9024801850318909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:55<00:00,  1.93s/it, loss=0.0134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 250359535/250937344 with acc 99.77\n",
      "Dice score: 0.8788880705833435\n",
      "Got 6540014/6553600 with acc 99.79\n",
      "Dice score: 0.893551230430603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:55<00:00,  1.93s/it, loss=0.0125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 250442277/250937344 with acc 99.80\n",
      "Dice score: 0.8997586965560913\n",
      "Got 6540232/6553600 with acc 99.80\n",
      "Dice score: 0.8968640565872192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:55<00:00,  1.93s/it, loss=0.0111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 250299390/250937344 with acc 99.75\n",
      "Dice score: 0.873737096786499\n",
      "Got 6538084/6553600 with acc 99.76\n",
      "Dice score: 0.8850079774856567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:55<00:00,  1.93s/it, loss=0.0109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 250410401/250937344 with acc 99.79\n",
      "Dice score: 0.8973494172096252\n",
      "Got 6539688/6553600 with acc 99.79\n",
      "Dice score: 0.8966012001037598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:55<00:00,  1.93s/it, loss=0.0127] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 250452260/250937344 with acc 99.81\n",
      "Dice score: 0.9054688215255737\n",
      "Got 6540615/6553600 with acc 99.80\n",
      "Dice score: 0.901900053024292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:55<00:00,  1.93s/it, loss=0.0104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 250447279/250937344 with acc 99.80\n",
      "Dice score: 0.9010977745056152\n",
      "Got 6540653/6553600 with acc 99.80\n",
      "Dice score: 0.9002535343170166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:55<00:00,  1.93s/it, loss=0.0101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Got 250449479/250937344 with acc 99.81\n",
      "Dice score: 0.9038371443748474\n",
      "Got 6539723/6553600 with acc 99.79\n",
      "Dice score: 0.8917149305343628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 43/60 [01:23<00:32,  1.93s/it, loss=0.00954]"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39854510-9708-409f-9e10-25eb936d503e",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665db73-8a3a-4a1f-adab-43f7643da97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd399f7e-ef68-46f4-8848-13c02ab67f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path, img_mask_path, index, folder=\"results/\"):\n",
    "    model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n",
    "    model.eval()\n",
    "    transformer = A.Compose(\n",
    "            [\n",
    "                A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "                A.Normalize(\n",
    "                    mean=[0.0, 0.0, 0.0],\n",
    "                    std=[1.0, 1.0, 1.0],\n",
    "                    max_pixel_value=255.0,\n",
    "                ),\n",
    "                ToTensorV2(),\n",
    "            ],\n",
    "        )\n",
    "    img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "    img_mask = torch.from_numpy(np.array(Image.open(img_mask_path).convert(\"L\")))\n",
    "    img_tensor = transformer(image=img)[\"image\"].unsqueeze(0).to(device=DEVICE)\n",
    "    # print(img_tensor.shape)\n",
    "    with torch.no_grad():\n",
    "        preds = torch.sigmoid(model(img_tensor))\n",
    "        preds = (preds > 0.5).float()\n",
    "        torchvision.utils.save_image(\n",
    "            preds, f\"{folder}pred_{index}.png\"\n",
    "        )\n",
    "        torchvision.utils.save_image(\n",
    "            img_tensor.cpu(), f\"{folder}og_{index}.png\"\n",
    "        )\n",
    "        preds = preds.squeeze(0).cpu().numpy()\n",
    "        # print(preds.shape)\n",
    "        # print(img_tensor.shape)\n",
    "        # print(preds[0])\n",
    "        for i in range(preds.shape[1]):\n",
    "            for j in range(preds.shape[2]):\n",
    "                if preds[0, i, j] == 1:\n",
    "                    # print(i, j)\n",
    "                    img_tensor[0,:, i,j] = torch.tensor((255, 0, 0))\n",
    "        torchvision.utils.save_image(\n",
    "            img_tensor, f\"{folder}final_{index}.png\"\n",
    "        )\n",
    "        shutil.copyfile(img_mask_path, f\"{folder}img_mask_{index}.png\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2a01b-2758-4bdb-9a10-3bc30f1a9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"MRI Dataset/val_images/TCGA_DU_7010_19860307_31.tif\", \"MRI Dataset/val_mask/TCGA_DU_7010_19860307_31_mask.tif\", 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
